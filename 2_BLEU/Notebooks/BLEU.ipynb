{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('asap-sas/train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  EssaySet  Score1  Score2  \\\n",
      "0   1         1       1       1   \n",
      "1   2         1       1       1   \n",
      "2   3         1       1       1   \n",
      "3   4         1       0       0   \n",
      "4   5         1       2       2   \n",
      "\n",
      "                                           EssayText  \n",
      "0  Some additional information that we would need...  \n",
      "1  After reading the expirement, I realized that ...  \n",
      "2  What you need is more trials, a control set up...  \n",
      "3  The student should list what rock is better an...  \n",
      "4  For the students to be able to make a replicat...  \n",
      "17207\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))\n",
    "print(df.count()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max score for essay 1 is 3\n",
      "Max score for essay 2 is 3\n",
      "Max score for essay 3 is 2\n",
      "Max score for essay 4 is 2\n",
      "Max score for essay 5 is 3\n",
      "Max score for essay 6 is 3\n",
      "Max score for essay 7 is 2\n",
      "Max score for essay 8 is 2\n",
      "Max score for essay 9 is 2\n",
      "Max score for essay 10 is 2\n"
     ]
    }
   ],
   "source": [
    "essay_set_list = (df['EssaySet'].unique())\n",
    "max_score_list = []\n",
    "for i in essay_set_list:\n",
    "    max_score_list.append(df[df['EssaySet']==i]['Score1'].max())\n",
    "    print('Max score for essay {} is {}'.format(i, max_score_list[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = pd.DataFrame()\n",
    "candidates = pd.DataFrame()\n",
    "\n",
    "for i in essay_set_list:\n",
    "    ref = df[(df['EssaySet']==i) & (df['Score1']==max_score_list[i-1])]\n",
    "    ref_list = [reference, ref]\n",
    "    reference = pd.concat(ref_list)\n",
    "    cands = df[(df['EssaySet']==i) & (df['Score1']!=max_score_list[i-1])]\n",
    "    cand_list = [candidates, cands]\n",
    "    candidates = pd.concat(cand_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Score2</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Some additional information that we would need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>After reading the expirement, I realized that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What you need is more trials, a control set up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The student should list what rock is better an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>For the students to be able to make a replicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  EssaySet  Score1  Score2  \\\n",
       "0   1         1       1       1   \n",
       "1   2         1       1       1   \n",
       "2   3         1       1       1   \n",
       "3   4         1       0       0   \n",
       "4   5         1       2       2   \n",
       "\n",
       "                                           EssayText  \n",
       "0  Some additional information that we would need...  \n",
       "1  After reading the expirement, I realized that ...  \n",
       "2  What you need is more trials, a control set up...  \n",
       "3  The student should list what rock is better an...  \n",
       "4  For the students to be able to make a replicat...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3712 13495 17207\n",
      "[ 1  2  3  4  5  6  7  8  9 10] [ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "total_ref = reference.count()[0]\n",
    "total_cand = candidates.count()[0]\n",
    "print(total_ref, total_cand, total_ref+total_cand)\n",
    "\n",
    "essay_set_list_ref = (reference['EssaySet'].unique())\n",
    "essay_set_list_cand = (candidates['EssaySet'].unique())\n",
    "print(essay_set_list_ref, essay_set_list_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]','', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = df.loc[(df['Score1']==1) & (df['EssaySet']!=3)]\n",
    "ref.head(5)\n",
    "ref.loc[0]['EssaySet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genearting the corpus\n",
    "\n",
    "reference_corpus = []\n",
    "candidate_corpus = []\n",
    "\n",
    "for i in essay_set_list:\n",
    "    ref = reference.loc[reference['EssaySet']==i]\n",
    "    cand = candidates.loc[candidates['EssaySet']==i]\n",
    "    \n",
    "    count_ref = ref.count()[0]\n",
    "    count_cand = cand.count()[0]\n",
    "    \n",
    "    ref_list = []\n",
    "    cand_list = []\n",
    "    \n",
    "    for j in range(count_ref):\n",
    "        ref_list.append(list(ref.iloc[j]['EssayText'].split()))\n",
    "    ref_tuple = (i, ref_list)\n",
    "    reference_corpus.append(ref_tuple)\n",
    "    \n",
    "    for j in range(count_cand):\n",
    "        cand_list.append(list(cand.iloc[j]['EssayText'].split()))\n",
    "    cand_tuple = (i, cand_list)\n",
    "    candidate_corpus.append(cand_tuple)\n",
    "\n",
    "reference_corpus = dict(reference_corpus)\n",
    "candidate_corpus = dict(candidate_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_corpus = list(reference_corpus.values())\n",
    "candidate_corpus = list(candidate_corpus.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reference_corpus = []\n",
    "new_candidate_corpus = []\n",
    "\n",
    "for i in essay_set_list:\n",
    "    ref_list = []\n",
    "    cand_list = []\n",
    "    for j in range(len(reference_corpus[i-1])):\n",
    "        ref_list.append(to_lowercase(remove_punctuation(reference_corpus[i-1][j])))\n",
    "    for j in range(len(candidate_corpus[i-1])):\n",
    "        cand_list.append(to_lowercase(remove_punctuation(candidate_corpus[i-1][j])))\n",
    "    ref_tuple = (i, ref_list)\n",
    "    cand_tuple = (i, cand_list)\n",
    "    new_reference_corpus.append(ref_tuple)\n",
    "    new_candidate_corpus.append(cand_tuple)\n",
    "\n",
    "new_reference_corpus = dict(new_reference_corpus)\n",
    "new_candidate_corpus = dict(new_candidate_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_corpus = list(new_reference_corpus.values())\n",
    "candidate_corpus = list(new_candidate_corpus.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5309973045822103\n"
     ]
    }
   ],
   "source": [
    "def get_ngrams(segment, max_order=4):\n",
    "    ngram_counts = collections.Counter()\n",
    "    for order in range(1, max_order + 1):\n",
    "        for i in range(0, len(segment) - order + 1):\n",
    "            ngram = tuple(segment[i:i+order])\n",
    "            ngram_counts[ngram] += 1\n",
    "\n",
    "    return ngram_counts\n",
    "\n",
    "def best_match_length(reference, candidate):\n",
    "    ref_length_list = []\n",
    "    for ref in reference:\n",
    "        ref_length_list.append(len(ref))\n",
    "    cand_length_list = [len(candidate)]*len(ref_length_list)\n",
    "    difference = np.abs((np.asarray(ref_length_list) - np.asarray(cand_length_list)))\n",
    "    if 0 in difference:\n",
    "        return ref_length_list[np.argmin(difference)]\n",
    "    else:\n",
    "        final = []\n",
    "        final.append(x for x in difference if x<0)\n",
    "        if ~(final):\n",
    "            return len(candidate)\n",
    "        else:\n",
    "            final = np.asarray(final)\n",
    "            return ref_length_list[np.argmax(final)]\n",
    "            \n",
    "\n",
    "def modified_precision(reference, candidate, order=4):\n",
    "    candidate_counts = get_ngrams(candidate, order)\n",
    "    \n",
    "    max_counts = {}\n",
    "    \n",
    "    for ref in reference:\n",
    "        ref_counts = get_ngrams(ref, order)\n",
    "        \n",
    "        for ngrams in candidate_counts:\n",
    "            max_counts[ngrams] = max(max_counts.get(ngrams, 0), ref_counts[ngrams])\n",
    "    \n",
    "    clipped_counts = {\n",
    "        ngram: min(count, max_counts[ngram]) for ngram, count in candidate_counts.items()\n",
    "    }\n",
    "    numer = sum(clipped_counts.values())\n",
    "    denom = max(1, sum(candidate_counts.values()))\n",
    "    \n",
    "    return numer/denom\n",
    "\n",
    "def BP(r, c):\n",
    "    if c>r:\n",
    "        return 1\n",
    "    elif c == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return math.exp(1-(r/c))\n",
    "# print(best_match_length(reference_corpus[0][0], candidate_corpus[0][500]), len(candidate_corpus[0][500]))\n",
    "# print(modified_precision(reference_corpus[0], candidate_corpus[0][0], 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLEU(reference, candidate, order=4):\n",
    "    precision = np.zeros((1, order))\n",
    "    p_log_sum = 0\n",
    "    \n",
    "    no_references = len(reference)\n",
    "    candidate_length = len(candidate)\n",
    "    for i in range(order):\n",
    "        precision[0][i] = modified_precision(reference, candidate, i+1)\n",
    "    \n",
    "    r = best_match_length(reference, candidate)\n",
    "    c = candidate_length\n",
    "    \n",
    "    bp = BP(r,c)\n",
    "    \n",
    "    weight = 1/order\n",
    "    \n",
    "    if (np.min(precision)>0):\n",
    "        for i in range(order):\n",
    "            p_log_sum += (weight * math.log(precision[0][i]))\n",
    "        geo_mean = math.exp(p_log_sum)\n",
    "    else:\n",
    "        geo_mean = 0\n",
    "    \n",
    "    bleu = bp*geo_mean\n",
    "    \n",
    "    return bleu    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9190499638456741"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(BLEU(reference_corpus[0], candidate_corpus[0][1000], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "ref = []\n",
    "ref.append(list(reference_corpus[0]))\n",
    "print(len(ref))\n",
    "cand = []\n",
    "cand.append(list(candidate_corpus[0][1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8574312041458294"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.translate.bleu_score.corpus_bleu(ref, cand)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
